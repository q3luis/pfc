{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Primer experimento :\n",
    "\n",
    "## Descripcion :\n",
    "Cambiamos el tamaño del batch para reducir el error,la prueba que se va a realizar es entrenar 1 modelo por secuencia y luego contrastar los resultados contra las demas secuencias.\n",
    "\n",
    "## Datos de entrada:\n",
    "\n",
    "Se esta usando la secuencias individuales de la libreria VIDRILO.\n",
    "Tambien para la transformacion inicial se usa la media de cada dataset que se vaya a usar como modelo , como es una prueba en la que no se va a optimizar el entrenamiento de cada secuencia la media solo se calcula sobre el conjunto con el que se va a entrenar. Ejemplo en el caso de entrenar el model sobre la primera secuencia , la media se calcula sobre esta.\n",
    "\n",
    "## Ajustes del entrenamiento:\n",
    "\n",
    "Numero de iteraciones : 35000\n",
    "Tamaño del mini batch : 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import caffe\n",
    "import lmdb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from caffe.proto import caffe_pb2\n",
    "from caffe.io import datum_to_array, array_to_datum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blob = caffe.proto.caffe_pb2.BlobProto()\n",
    "data = open( '/vol/pfc/data/means/Sequence5_mean.binaryproto' , 'rb' ).read()\n",
    "blob.ParseFromString(data)\n",
    "arr = np.array( caffe.io.blobproto_to_array(blob) )\n",
    "out = arr[0]\n",
    "#np.save( '/vol/pfc/data/means/Sequence5_mean.npy', out )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(image_in):\n",
    "    net.blobs['data'].data[...] = image_in\n",
    "    out = net.forward()\n",
    "    top_k = net.blobs['prob'].data[0].flatten().argsort()[-1:-6:-1]\n",
    "    output_prob = out['prob'][0]\n",
    "    print 'predicted class is:', output_prob.argmax()\n",
    "    return output_prob.argmax()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datum = caffe.proto.caffe_pb2.Datum()\n",
    "caffe.set_mode_cpu()\n",
    "\n",
    "def load_sequence(path):\n",
    "    lmdb_env = lmdb.open(path)\n",
    "    lmdb_txn = lmdb_env.begin()\n",
    "    lmdb_cursor = lmdb_txn.cursor()\n",
    "    return lmdb_cursor\n",
    "\n",
    "def load_model(model_path):\n",
    "    deploy_path=\"/vol/pfc/prototxt/sequence1/train_sequence_25_lmdb_deploy.prototxt\"    \n",
    "    #net = caffe.Net(deploy_path,model_path, caffe.TEST)\n",
    "    net = caffe.Classifier(deploy_path, model_path,\n",
    "                       mean=np.load('/vol/pfc/data/means/Sequence1_mean.npy').mean(1).mean(1),\n",
    "                       channel_swap=(2,1,0),\n",
    "                       raw_scale=255,\n",
    "                          image_dims=(320, 240))\n",
    "    return net\n",
    "   \n",
    "def load_transform(net,mean_path):\n",
    "    transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
    "    transformer.set_mean('data', np.load(mean_path).mean(1).mean(1))\n",
    "    transformer.set_transpose('data', (2,0,1))\n",
    "    return transformer\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequences=[\"/vol/pfc/data/datasets/Sequence1_lmdb\",\"/vol/pfc/data/datasets/Sequence2_lmdb\"\n",
    "           ,\"/vol/pfc/data/datasets/Sequence3_lmdb\",\"/vol/pfc/data/datasets/Sequence4_lmdb\"\n",
    "           ,\"/vol/pfc/data/datasets/Sequence5_lmdb\"]\n",
    "\n",
    "models=[\"/mnt/models/train_25_batch/train_sequence_1_50_lmdb_iter_35000.caffemodel\",\"/mnt/model/train_25_batch/train_sequence_2_50_lmdb_iter_35000.caffemodel\"\n",
    "       ,\"/mnt/models/train_25_batch/train_sequence_3_50_lmdb_iter_35000.caffemodel\",\"/mnt/model/train_25_batch/train_sequence_4_50_lmdb_iter_35000.caffemodel\"\n",
    "       ,\"/mnt/models/train_50_batch/train_sequence_5_50_lmdb_iter_35000.caffemodel\"]\n",
    "\n",
    "means=[\"/vol/pfc/data/means/Sequence1_mean.npy\",\"/vol/pfc/data/means/Sequence2_mean.npy\",\"/vol/pfc/data/means/Sequence3_mean.npy\"\n",
    "       ,\"/vol/pfc/data/means/Sequence4_mean.npy\",\"/vol/pfc/data/means/Sequence5_mean.npy\"]\n",
    "\n",
    "deploys=[\"/vol/pfc/prototxt/sequence1/train_sequence_25_lmdb_deploy.prototxt\",\"/vol/pfc/prototxt/sequence2/train_sequence_25_lmdb_deploy.prototxt\"\n",
    "        ,\"/vol/pfc/prototxt/sequence3/train_sequence_25_lmdb_deploy.prototxt\",\"/vol/pfc/prototxt/sequence4/train_sequence_25_lmdb_deploy.prototxt\"\n",
    "        ,\"/vol/pfc/prototxt/sequence5/train_sequence_25_lmdb_deploy.prototxt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_sequence(net,sequence,transform):\n",
    "    data_array = []\n",
    "    for key, value in sequence:\n",
    "        datum.ParseFromString(value)\n",
    "        label = datum.label\n",
    "        data = caffe.io.datum_to_array(datum)\n",
    "        image = np.transpose(data,(1, 2, 0))\n",
    "        #prediccion = predict(transform.preprocess('data', image))\n",
    "        prediction = net.predict([transform.preprocess('data', image)])\n",
    "        \n",
    "        data_array.append((label,prediccion)) \n",
    "        print \" label \"+str(label)+\" preiccion \"+str(prediccion)\n",
    "    \n",
    "    return data_array\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "len_model=len(models)\n",
    "len_sequences=len(sequences)\n",
    "len_model=2\n",
    "len_sequences=2\n",
    "data_evaluate=[[]]\n",
    "for i in range(0,len_model-1):\n",
    "    model=models[i]\n",
    "    print 'evalua el  modelo: '+str(model)\n",
    "    net=load_model(model)\n",
    "    transform=load_transform(net,means[i])\n",
    "    \n",
    "    for j in range(0,len_sequences-1):\n",
    "        print 'evalua sequence '+str(sequences[j])\n",
    "        data=load_sequence(sequences[j])\n",
    "        data_evaluate=process_sequence(net,data,transform)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
