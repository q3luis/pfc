{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Primer experimento :\n",
    "\n",
    "## Descripcion :\n",
    "La primera prueba que se va a realizar es entrenar 1 modelo por secuencia y luego contrastar los resultados contra las demas secuencias.\n",
    "\n",
    "## Datos de entrada:\n",
    "\n",
    "Se esta usando la secuencias individuales de la libreria VIDRILO.\n",
    "Tambien para la transformacion inicial se usa la media de cada dataset que se vaya a usar como modelo , como es una prueba en la que no se va a optimizar el entrenamiento de cada secuencia la media solo se calcula sobre el conjunto con el que se va a entrenar. Ejemplo en el caso de entrenar el model sobre la primera secuencia , la media se calcula sobre esta.\n",
    "\n",
    "## Ajustes del entrenamiento:\n",
    "\n",
    "Numero de iteraciones : 35000\n",
    "Tamaño del mini batch : 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Inicializamos las librerias de cafe\n",
    "import caffe\n",
    "import lmdb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from caffe.proto import caffe_pb2\n",
    "from caffe.io import datum_to_array, array_to_datum\n",
    "\n",
    "#from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blob = caffe.proto.caffe_pb2.BlobProto()\n",
    "data = open( '/vol/pfc/data/means/Sequence2_mean.binaryproto' , 'rb' ).read()\n",
    "blob.ParseFromString(data)\n",
    "arr = np.array( caffe.io.blobproto_to_array(blob) )\n",
    "out = arr[0]\n",
    "#np.save( '/vol/pfc/data/means/Sequence2_mean.npy', out )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Funcion que no sirve para hacer la prediccion\n",
    "def predict(net,image_in):\n",
    "    net.blobs['data'].data[...] = image_in\n",
    "    out = net.forward()\n",
    "    top_k = net.blobs['prob'].data[0].flatten().argsort()[-1:-6:-1]\n",
    "    output_prob = out['prob'][0]\n",
    "    #print 'predicted class is:', output_prob.argmax()\n",
    "    return output_prob.argmax()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "datum = caffe.proto.caffe_pb2.Datum()\n",
    "# Caffe en modo gpu para evaluar mas rapido\n",
    "caffe.set_mode_gpu()\n",
    "\n",
    "\n",
    "\n",
    "def load_sequence(path):\n",
    "    lmdb_env = lmdb.open(path)\n",
    "    lmdb_txn = lmdb_env.begin()\n",
    "    lmdb_cursor = lmdb_txn.cursor()\n",
    "    return lmdb_cursor\n",
    "\n",
    "def load_model(model_path,deploy_path):\n",
    "    #deploy_path=\"/vol/pfc/prototxt/sequence1/train_sequence_25_lmdb_deploy.prototxt\"    \n",
    "    net = caffe.Net(deploy_path,model_path, caffe.TEST)\n",
    "    return net\n",
    "   \n",
    "def load_transform(net,mean_path):\n",
    "    transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
    "    transformer.set_mean('data', np.load(mean_path).mean(1).mean(1))\n",
    "    transformer.set_transpose('data', (2,0,1))\n",
    "    return transformer\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequences=[\"/vol/pfc/data/datasets/Sequence1_lmdb\",\"/vol/pfc/data/datasets/Sequence2_lmdb\"\n",
    "           ,\"/vol/pfc/data/datasets/Sequence3_lmdb\",\"/vol/pfc/data/datasets/Sequence4_lmdb\"\n",
    "           ,\"/vol/pfc/data/datasets/Sequence5_lmdb\"]\n",
    "\n",
    "models=[\"/mnt/model/train_25_batch/train_sequence_1_25_lmdb_iter_35000.caffemodel\",\"/mnt/model/train_25_batch/train_sequence_2_25_lmdb_iter_35000.caffemodel\"\n",
    "       ,\"/mnt/model/train_25_batch/train_sequence_4_25_lmdb_iter_35000.caffemodel\"\n",
    "       ,\"/mnt/model/train_25_batch/train_sequence_5_25_lmdb_iter_35000.caffemodel\"]\n",
    "\n",
    "means=[\"/vol/pfc/data/means/Sequence1_mean.npy\",\"/vol/pfc/data/means/Sequence2_mean.npy\"\n",
    "       ,\"/vol/pfc/data/means/Sequence4_mean.npy\",\"/vol/pfc/data/means/Sequence5_mean.npy\"]\n",
    "\n",
    "deploys=[\"/vol/pfc/prototxt/sequence1/train_sequence_25_lmdb_deploy.prototxt\",\"/vol/pfc/prototxt/sequence2/train_sequence_25_lmdb_deploy.prototxt\"\n",
    "        ,\"/vol/pfc/prototxt/sequence4/train_sequence_25_lmdb_deploy.prototxt\"\n",
    "        ,\"/vol/pfc/prototxt/sequence5/train_sequence_25_lmdb_deploy.prototxt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_sequence(net,sequence,transform):\n",
    "    data_array = []\n",
    "    cnt=0\n",
    "    for key, value in sequence:\n",
    "        datum.ParseFromString(value)\n",
    "        label = datum.label\n",
    "        data = caffe.io.datum_to_array(datum)\n",
    "        image = np.transpose(data,(1, 2, 0))\n",
    "        prediccion = predict(transform.preprocess('data', image))\n",
    "        data_array.append((label,prediccion)) \n",
    "        #print \" label \"+str(label)+\" preiccion \"+str(prediccion)\n",
    "      #  cnt+=1\n",
    "      #  if(cnt>100):\n",
    "      #      break\n",
    "        \n",
    "    return data_array\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inicio\n",
      "evalua el  modelo: /mnt/model/train_25_batch/train_sequence_1_25_lmdb_iter_35000.caffemodel\n",
      "evalua sequence /vol/pfc/data/datasets/Sequence1_lmdb\n",
      "evalua sequence /vol/pfc/data/datasets/Sequence2_lmdb\n",
      "evalua sequence /vol/pfc/data/datasets/Sequence3_lmdb\n",
      "evalua sequence /vol/pfc/data/datasets/Sequence4_lmdb\n",
      "evalua sequence /vol/pfc/data/datasets/Sequence5_lmdb\n",
      "end /mnt/model/train_25_batch/train_sequence_1_25_lmdb_iter_35000.caffemodel\n",
      "evalua el  modelo: /mnt/model/train_25_batch/train_sequence_2_25_lmdb_iter_35000.caffemodel\n",
      "evalua sequence /vol/pfc/data/datasets/Sequence1_lmdb\n",
      "evalua sequence /vol/pfc/data/datasets/Sequence2_lmdb\n",
      "evalua sequence /vol/pfc/data/datasets/Sequence3_lmdb\n",
      "evalua sequence /vol/pfc/data/datasets/Sequence4_lmdb\n",
      "evalua sequence /vol/pfc/data/datasets/Sequence5_lmdb\n",
      "end /mnt/model/train_25_batch/train_sequence_2_25_lmdb_iter_35000.caffemodel\n",
      "evalua el  modelo: /mnt/model/train_25_batch/train_sequence_4_25_lmdb_iter_35000.caffemodel\n",
      "evalua sequence /vol/pfc/data/datasets/Sequence1_lmdb\n",
      "evalua sequence /vol/pfc/data/datasets/Sequence2_lmdb\n",
      "evalua sequence /vol/pfc/data/datasets/Sequence3_lmdb\n",
      "evalua sequence /vol/pfc/data/datasets/Sequence4_lmdb\n",
      "evalua sequence /vol/pfc/data/datasets/Sequence5_lmdb\n",
      "end /mnt/model/train_25_batch/train_sequence_4_25_lmdb_iter_35000.caffemodel\n",
      "evalua el  modelo: /mnt/model/train_25_batch/train_sequence_5_25_lmdb_iter_35000.caffemodel\n",
      "evalua sequence /vol/pfc/data/datasets/Sequence1_lmdb\n",
      "evalua sequence /vol/pfc/data/datasets/Sequence2_lmdb\n",
      "evalua sequence /vol/pfc/data/datasets/Sequence3_lmdb\n",
      "evalua sequence /vol/pfc/data/datasets/Sequence4_lmdb\n",
      "evalua sequence /vol/pfc/data/datasets/Sequence5_lmdb\n",
      "end /mnt/model/train_25_batch/train_sequence_5_25_lmdb_iter_35000.caffemodel\n"
     ]
    }
   ],
   "source": [
    "\n",
    "len_model=len(models)\n",
    "len_sequences=len(sequences)\n",
    "print \"inicio\"\n",
    "data_evaluate2=[]\n",
    "for i in range(0,len_model):\n",
    "    model=models[i]\n",
    "    deploy=deploys[i]\n",
    "    print 'evalua el  modelo: '+str(model)\n",
    "    net=load_model(model,deploy)\n",
    "    transform=load_transform(net,means[i])\n",
    "    data_evaluate2.append([])\n",
    "    for j in range(0,len_sequences):\n",
    "        print 'evalua sequence '+str(sequences[j])\n",
    "        data=load_sequence(sequences[j])\n",
    "        data_evaluate2[i].append(process_sequence(net,data,transform))\n",
    "    print \"end \"+str(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_evaluate2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seq_model_label=['seq1_model','seq2_model','seq4_model','seq5_model']\n",
    "seq_dataset_label=['seq1','seq2','seq3','seq4','seq5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_accuracy(y):\n",
    "    y_real=y[:,0]\n",
    "    y_pred=y[:,1]\n",
    "    metrics= y_real==y_pred\n",
    "    accuracy =(np.sum(metrics)*100.0)/len(metrics)\n",
    "    #print \"accruracy \"+\"{:10.4f}\".format(accuracy) +\"%\"\n",
    "    return \"{:10.4f}\".format(accuracy)+\"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model seq1_model\n",
      " seq1:    26.9987% seq2:    26.8618% seq3:    28.1584% seq4:    26.3572% seq5:    17.7841%\n",
      "model seq2_model\n",
      " seq1:    32.4822% seq2:    32.9985% seq3:    29.8043% seq4:    31.9726% seq5:    20.5659%\n",
      "model seq4_model\n",
      " seq1:    31.0590% seq2:    32.0157% seq3:    30.6050% seq4:    31.2681% seq5:    20.1854%\n",
      "model seq5_model\n",
      " seq1:    20.5525% seq2:    20.9216% seq3:    19.7064% seq4:    21.4671% seq5:    15.4660%\n"
     ]
    }
   ],
   "source": [
    "len_data_evaluate_model=len(data_evaluate2)\n",
    "\n",
    "for i in range(0,len_data_evaluate_model):\n",
    "    len_dataset_evaluate=len(data_evaluate2[i])\n",
    "    seq_for_model=data_evaluate2[i]\n",
    "    print \"model \"+seq_model_label[i]\n",
    "    result_line=\"\"\n",
    "    for j in range(0,len_dataset_evaluate):\n",
    "        result_line+=\" \"+seq_dataset_label[j]+\": \"+(get_accuracy(np.array(seq_for_model[j])))\n",
    "    \n",
    "    print result_line\n",
    "                            \n",
    "                                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tiempo de entrenamiento:\n",
    "\n",
    "El tiempo de entrenamiento esta desde 3h y 3 minutos a 4 horas depende del tamaño de la secuencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_evaluate2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f4c1cca3deca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_evaluate2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0my_real\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_real\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_evaluate2' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "y=data_evaluate2[0]\n",
    "y_real=y[:,0]\n",
    "y_pred=y[:,1]\n",
    "confusion_matrix(y_real, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
