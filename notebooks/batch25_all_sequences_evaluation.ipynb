{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Primer experimento :\n",
    "\n",
    "## Descripcion :\n",
    "La primera prueba que se va a realizar es entrenar 1 modelo por secuencia y luego contrastar los resultados contra las demas secuencias.\n",
    "\n",
    "## Datos de entrada:\n",
    "\n",
    "Se esta usando la secuencias individuales de la libreria VIDRILO.\n",
    "Tambien para la transformacion inicial se usa la media de cada dataset que se vaya a usar como modelo , como es una prueba en la que no se va a optimizar el entrenamiento de cada secuencia la media solo se calcula sobre el conjunto con el que se va a entrenar. Ejemplo en el caso de entrenar el model sobre la primera secuencia , la media se calcula sobre esta.\n",
    "\n",
    "## Ajustes del entrenamiento:\n",
    "\n",
    "Numero de iteraciones : 35000\n",
    "Tama√±o del mini batch : 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name parallel",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-71666c0e3fb0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcaffe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatum_to_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marray_to_datum\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/lib/python2.7/dist-packages/sklearn/metrics/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mauc_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mscorer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmake_scorer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSCORERS\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcluster\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/dist-packages/sklearn/metrics/scorer.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m                recall_score, log_loss)\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0madjusted_rand_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexternals\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/dist-packages/sklearn/metrics/cluster/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0msupervised\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mv_measure_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0msupervised\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0munsupervised\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msilhouette_samples\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0munsupervised\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msilhouette_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbicluster\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconsensus_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/dist-packages/sklearn/metrics/cluster/unsupervised.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpairwise\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpairwise_distances\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexternals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoblib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mParallel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexternals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoblib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdelayed\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexternals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoblib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mparallel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpairwise_fast\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_chi2_kernel_fast\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name parallel"
     ]
    }
   ],
   "source": [
    "# Inicializamos las librerias de cafe\n",
    "import caffe\n",
    "import lmdb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from caffe.proto import caffe_pb2\n",
    "from caffe.io import datum_to_array, array_to_datum\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/pylab/config.py:66: DeprecationWarning: metadata {'config': True} was set from the constructor.  Metadata should be set using the .tag() method, e.g., Int().tag(key1='value1', key2='value2')\n",
      "  inline backend.\"\"\"\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/pylab/config.py:71: DeprecationWarning: metadata {'config': True} was set from the constructor.  Metadata should be set using the .tag() method, e.g., Int().tag(key1='value1', key2='value2')\n",
      "  'retina', 'jpeg', 'svg', 'pdf'.\"\"\")\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/pylab/config.py:85: DeprecationWarning: metadata {'config': True} was set from the constructor.  Metadata should be set using the .tag() method, e.g., Int().tag(key1='value1', key2='value2')\n",
      "  use `figure_formats` instead)\"\"\")\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/pylab/config.py:95: DeprecationWarning: metadata {'config': True} was set from the constructor.  Metadata should be set using the .tag() method, e.g., Int().tag(key1='value1', key2='value2')\n",
      "  \"\"\"\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/pylab/config.py:114: DeprecationWarning: metadata {'config': True} was set from the constructor.  Metadata should be set using the .tag() method, e.g., Int().tag(key1='value1', key2='value2')\n",
      "  \"\"\")\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/pylab/config.py:44: DeprecationWarning: InlineBackend._config_changed is deprecated: use @observe and @unobserve instead.\n",
      "  def _config_changed(self, name, old, new):\n",
      "/usr/local/lib/python2.7/dist-packages/traitlets/traitlets.py:770: DeprecationWarning: A parent of InlineBackend._config_changed has adopted the new @observe(change) API\n",
      "  clsname, change_or_name), DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blob = caffe.proto.caffe_pb2.BlobProto()\n",
    "data = open( '/vol/pfc/data/means/Sequence2_mean.binaryproto' , 'rb' ).read()\n",
    "blob.ParseFromString(data)\n",
    "arr = np.array( caffe.io.blobproto_to_array(blob) )\n",
    "out = arr[0]\n",
    "#np.save( '/vol/pfc/data/means/Sequence2_mean.npy', out )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Funcion que no sirve para hacer la prediccion\n",
    "def predict(image_in):\n",
    "    net.blobs['data'].data[...] = image_in\n",
    "    out = net.forward()\n",
    "    top_k = net.blobs['prob'].data[0].flatten().argsort()[-1:-6:-1]\n",
    "    output_prob = out['prob'][0]\n",
    "    #print 'predicted class is:', output_prob.argmax()\n",
    "    return output_prob.argmax()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "datum = caffe.proto.caffe_pb2.Datum()\n",
    "# Caffe en modo gpu para evaluar mas rapido\n",
    "caffe.set_mode_gpu()\n",
    "\n",
    "def load_sequence(path):\n",
    "    lmdb_env = lmdb.open(path)\n",
    "    lmdb_txn = lmdb_env.begin()\n",
    "    lmdb_cursor = lmdb_txn.cursor()\n",
    "    return lmdb_cursor\n",
    "\n",
    "def load_model(model_path,deploy_path):\n",
    "    #deploy_path=\"/vol/pfc/prototxt/sequence1/train_sequence_25_lmdb_deploy.prototxt\"    \n",
    "    net = caffe.Net(deploy_path,model_path, caffe.TEST)\n",
    "    return net\n",
    "   \n",
    "def load_transform(net,mean_path):\n",
    "    transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
    "    transformer.set_mean('data', np.load(mean_path).mean(1).mean(1))\n",
    "    transformer.set_transpose('data', (2,0,1))\n",
    "    return transformer\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequences=[\"/vol/pfc/data/datasets/Sequence1_lmdb\",\"/vol/pfc/data/datasets/Sequence2_lmdb\"\n",
    "           ,\"/vol/pfc/data/datasets/Sequence3_lmdb\",\"/vol/pfc/data/datasets/Sequence4_lmdb\"\n",
    "           ,\"/vol/pfc/data/datasets/Sequence5_lmdb\"]\n",
    "\n",
    "models=[\"/mnt/model/train_25_batch/train_sequence_1_25_lmdb_iter_35000.caffemodel\",\"/mnt/model/train_25_batch/train_sequence_2_25_lmdb_iter_35000.caffemodel\"\n",
    "       ,\"/mnt/model/train_25_batch/train_sequence_4_25_lmdb_iter_35000.caffemodel\"\n",
    "       ,\"/mnt/model/train_25_batch/train_sequence_5_25_lmdb_iter_35000.caffemodel\"]\n",
    "\n",
    "means=[\"/vol/pfc/data/means/Sequence1_mean.npy\",\"/vol/pfc/data/means/Sequence2_mean.npy\"\n",
    "       ,\"/vol/pfc/data/means/Sequence4_mean.npy\",\"/vol/pfc/data/means/Sequence5_mean.npy\"]\n",
    "\n",
    "deploys=[\"/vol/pfc/prototxt/sequence1/train_sequence_25_lmdb_deploy.prototxt\",\"/vol/pfc/prototxt/sequence2/train_sequence_25_lmdb_deploy.prototxt\"\n",
    "        ,\"/vol/pfc/prototxt/sequence4/train_sequence_25_lmdb_deploy.prototxt\"\n",
    "        ,\"/vol/pfc/prototxt/sequence5/train_sequence_25_lmdb_deploy.prototxt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_sequence(net,sequence,transform):\n",
    "    data_array = []\n",
    "    cnt=0\n",
    "    for key, value in sequence:\n",
    "        datum.ParseFromString(value)\n",
    "        label = datum.label\n",
    "        data = caffe.io.datum_to_array(datum)\n",
    "        image = np.transpose(data,(1, 2, 0))\n",
    "        prediccion = predict(transform.preprocess('data', image))\n",
    "        data_array.append((label,prediccion)) \n",
    "        #print \" label \"+str(label)+\" preiccion \"+str(prediccion)\n",
    "      #  cnt+=1\n",
    "      #  if(cnt>100):\n",
    "      #      break\n",
    "        \n",
    "    return data_array\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inicio\n",
      "evalua el  modelo: /mnt/model/train_25_batch/train_sequence_1_25_lmdb_iter_35000.caffemodel\n",
      "evalua sequence /vol/pfc/data/datasets/Sequence1_lmdb\n",
      "evalua sequence /vol/pfc/data/datasets/Sequence2_lmdb\n",
      "evalua sequence /vol/pfc/data/datasets/Sequence3_lmdb\n",
      "evalua sequence /vol/pfc/data/datasets/Sequence4_lmdb\n",
      "evalua sequence /vol/pfc/data/datasets/Sequence5_lmdb\n",
      "end /mnt/model/train_25_batch/train_sequence_1_25_lmdb_iter_35000.caffemodel\n",
      "evalua el  modelo: /mnt/model/train_25_batch/train_sequence_2_25_lmdb_iter_35000.caffemodel\n",
      "evalua sequence /vol/pfc/data/datasets/Sequence1_lmdb\n",
      "evalua sequence /vol/pfc/data/datasets/Sequence2_lmdb\n",
      "evalua sequence /vol/pfc/data/datasets/Sequence3_lmdb\n",
      "evalua sequence /vol/pfc/data/datasets/Sequence4_lmdb\n",
      "evalua sequence /vol/pfc/data/datasets/Sequence5_lmdb\n",
      "end /mnt/model/train_25_batch/train_sequence_2_25_lmdb_iter_35000.caffemodel\n",
      "evalua el  modelo: /mnt/model/train_25_batch/train_sequence_4_25_lmdb_iter_35000.caffemodel\n",
      "evalua sequence /vol/pfc/data/datasets/Sequence1_lmdb\n",
      "evalua sequence /vol/pfc/data/datasets/Sequence2_lmdb\n",
      "evalua sequence /vol/pfc/data/datasets/Sequence3_lmdb\n",
      "evalua sequence /vol/pfc/data/datasets/Sequence4_lmdb\n",
      "evalua sequence /vol/pfc/data/datasets/Sequence5_lmdb\n",
      "end /mnt/model/train_25_batch/train_sequence_4_25_lmdb_iter_35000.caffemodel\n",
      "evalua el  modelo: /mnt/model/train_25_batch/train_sequence_5_25_lmdb_iter_35000.caffemodel\n",
      "evalua sequence /vol/pfc/data/datasets/Sequence1_lmdb\n",
      "evalua sequence /vol/pfc/data/datasets/Sequence2_lmdb\n",
      "evalua sequence /vol/pfc/data/datasets/Sequence3_lmdb\n",
      "evalua sequence /vol/pfc/data/datasets/Sequence4_lmdb\n",
      "evalua sequence /vol/pfc/data/datasets/Sequence5_lmdb\n",
      "end /mnt/model/train_25_batch/train_sequence_5_25_lmdb_iter_35000.caffemodel\n"
     ]
    }
   ],
   "source": [
    "\n",
    "len_model=len(models)\n",
    "len_sequences=len(sequences)\n",
    "print \"inicio\"\n",
    "data_evaluate2=[]\n",
    "for i in range(0,len_model):\n",
    "    model=models[i]\n",
    "    deploy=deploys[i]\n",
    "    print 'evalua el  modelo: '+str(model)\n",
    "    net=load_model(model,deploy)\n",
    "    transform=load_transform(net,means[i])\n",
    "    data_evaluate2.append([])\n",
    "    for j in range(0,len_sequences):\n",
    "        print 'evalua sequence '+str(sequences[j])\n",
    "        data=load_sequence(sequences[j])\n",
    "        data_evaluate2[i].append(process_sequence(net,data,transform))\n",
    "    print \"end \"+str(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_evaluate2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seq_model_label=['seq1_model','seq2_model','seq4_model','seq5_model']\n",
    "seq_dataset_label=['seq1','seq2','seq3','seq4','seq5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_accuracy(y):\n",
    "    y_real=y[:,0]\n",
    "    y_pred=y[:,1]\n",
    "    metrics= y_real==y_pred\n",
    "    accuracy =(np.sum(metrics)*100.0)/len(metrics)\n",
    "    #print \"accruracy \"+\"{:10.4f}\".format(accuracy) +\"%\"\n",
    "    return \"{:10.4f}\".format(accuracy)+\"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model seq1_model\n",
      " seq1:    26.9987% seq2:    26.8618% seq3:    28.1584% seq4:    26.3572% seq5:    17.7841%\n",
      "model seq2_model\n",
      " seq1:    32.4822% seq2:    32.9985% seq3:    29.8043% seq4:    31.9726% seq5:    20.5659%\n",
      "model seq4_model\n",
      " seq1:    31.0590% seq2:    32.0157% seq3:    30.6050% seq4:    31.2681% seq5:    20.1854%\n",
      "model seq5_model\n",
      " seq1:    20.5525% seq2:    20.9216% seq3:    19.7064% seq4:    21.4671% seq5:    15.4660%\n"
     ]
    }
   ],
   "source": [
    "len_data_evaluate_model=len(data_evaluate2)\n",
    "\n",
    "for i in range(0,len_data_evaluate_model):\n",
    "    len_dataset_evaluate=len(data_evaluate2[i])\n",
    "    seq_for_model=data_evaluate2[i]\n",
    "    print \"model \"+seq_model_label[i]\n",
    "    result_line=\"\"\n",
    "    for j in range(0,len_dataset_evaluate):\n",
    "        result_line+=\" \"+seq_dataset_label[j]+\": \"+(get_accuracy(np.array(seq_for_model[j])))\n",
    "    \n",
    "    print result_line\n",
    "                            \n",
    "                                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tiempo de entrenamiento:\n",
    "\n",
    "El tiempo de entrenamiento esta desde 3h y 3 minutos a 4 horas depende del tama√±o de la secuencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_evaluate2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f4c1cca3deca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_evaluate2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0my_real\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_real\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_evaluate2' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "y=data_evaluate2[0]\n",
    "y_real=y[:,0]\n",
    "y_pred=y[:,1]\n",
    "confusion_matrix(y_real, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
